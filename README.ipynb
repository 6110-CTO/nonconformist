{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conformal prediction\n",
    "\n",
    "Conformal predictors are predictive models that associate each of their predictions with a measure of statistically valid confidence. Given a test object $x_i$ and a user-specified significance level $\\epsilon \\in (0, 1)$, a conformal predictor outputs a prediction region $\\Gamma_i^{\\epsilon} \\subseteq Y$ that contains the true output value $y_i \\in Y$ with probability $1-\\epsilon$.\n",
    "\n",
    "# Suggested reading\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonconformist Usage:\n",
    "## 1. Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1a: Simple ICP (classification)\n",
    "In this example, we construct a simple inductive conformal predictor for classification, using a support vector classifier as the underlying model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False  True False]\n",
      " [False  True False]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from nonconformist.cp import IcpClassifier\n",
    "from nonconformist.nc import NcFactory\n",
    "    \n",
    "iris = load_iris()\n",
    "idx = np.random.permutation(iris.target.size)\n",
    "\n",
    "# Divide the data into proper training set, calibration set and test set\n",
    "idx_train, idx_cal, idx_test = idx[:50], idx[50:100], idx[100:]\n",
    "\n",
    "model = SVC(probability=True)\t# Create the underlying model\n",
    "nc = NcFactory.create_nc(model)\t# Create a default nonconformity function\n",
    "icp = IcpClassifier(nc)\t\t\t# Create an inductive conformal classifier\n",
    "\n",
    "# Fit the ICP using the proper training set\n",
    "icp.fit(iris.data[idx_train, :], iris.target[idx_train])\n",
    "\n",
    "# Calibrate the ICP using the calibration set\n",
    "icp.calibrate(iris.data[idx_cal, :], iris.target[idx_cal])\n",
    "\n",
    "# Produce predictions for the test set, with confidence 95%\n",
    "prediction = icp.predict(iris.data[idx_test, :], significance=0.05)\n",
    "\n",
    "# Print the first 5 predictions\n",
    "print(prediction[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a boolean numpy.array with shape (n_test, n_classes), where each row is a boolean vector denoting the class labels included in the prediction region at the specified significance level.\n",
    "\n",
    "For this particular example, we might obtain, for a given test object, a boolean vector [ True True False ], meaning that the $1-\\epsilon$ confidence prediction region contains class labels 0 and 1 (i.e., with 95% probability, one of these two classes will be correct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1b: Simple TCP (classification)\n",
    "In this example, we construct a simple transductive conformal predictor for classification, using a support vector classifier as the underlying model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False False]\n",
      " [ True False False]\n",
      " [ True False False]\n",
      " [False False  True]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from nonconformist.cp import TcpClassifier\n",
    "from nonconformist.nc import NcFactory\n",
    "    \n",
    "iris = load_iris()\n",
    "idx = np.random.permutation(iris.target.size)\n",
    "\n",
    "# Divide the data into training set and test set\n",
    "idx_train, idx_test = idx[:100], idx[100:]\n",
    "\n",
    "model = SVC(probability=True)\t# Create the underlying model\n",
    "nc = NcFactory.create_nc(model)\t# Create a default nonconformity function\n",
    "tcp = TcpClassifier(nc)\t\t\t# Create an transductive conformal classifier\n",
    "\n",
    "# Fit the TCP using the proper training set\n",
    "tcp.fit(iris.data[idx_train, :], iris.target[idx_train])\n",
    "\n",
    "# Produce predictions for the test set, with confidence 95%\n",
    "prediction = tcp.predict(iris.data[idx_test, :], significance=0.05)\n",
    "\n",
    "# Print the first 5 predictions\n",
    "print(prediction[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a result that is conceptually identical as in the previous example (although the particular output values might differ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1c: Simple ICP (regression)\n",
    "\n",
    "In this example, we construct a simple inductive conformal predictor for regression, this time using a random forest regression model as the underlying model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.8   21.6 ]\n",
      " [  8.5   21.3 ]\n",
      " [ 11.87  24.67]\n",
      " [  7.98  20.78]\n",
      " [  2.88  15.68]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from nonconformist.cp import IcpRegressor\n",
    "from nonconformist.nc import NcFactory\n",
    "    \n",
    "boston = load_boston()\n",
    "idx = np.random.permutation(boston.target.size)\n",
    "\n",
    "# Divide the data into proper training set, calibration set and test set\n",
    "idx_train, idx_cal, idx_test = idx[:300], idx[300:399], idx[399:]\n",
    "\n",
    "model = RandomForestRegressor()\t# Create the underlying model\n",
    "nc = NcFactory.create_nc(model)\t# Create a default nonconformity function\n",
    "icp = IcpRegressor(nc)\t\t\t# Create an inductive conformal classifier\n",
    "\n",
    "# Fit the ICP using the proper training set\n",
    "icp.fit(boston.data[idx_train, :], boston.target[idx_train])\n",
    "\n",
    "# Calibrate the ICP using the calibration set\n",
    "icp.calibrate(boston.data[idx_cal, :], boston.target[idx_cal])\n",
    "\n",
    "# Produce predictions for the test set, with confidence 95%\n",
    "prediction = icp.predict(boston.data[idx_test, :], significance=0.05)\n",
    "\n",
    "# Print the first 5 predictions\n",
    "print(prediction[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the result is a numerical numpy.array with shape (n_test, 2), where each row is a vector signifying the lower and upper bounds of an interval, denoting the prediction region at the specified significance level.\n",
    "\n",
    "For this particular example, we might obtain, for a given test object, a numerical vector [ 8.8  21.6 ], meaning that the $1-\\epsilon$ confidence prediction region is the interval $[8.8, 21.6]$ (i.e., with 95% probability, the correct output value lies somehwere on this interval)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nonconformity functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonconformist has built-in support for the most common nonconformity functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2a: Choosing your underlying model\n",
    "\n",
    "The simplest way of defining a nonconformity function based on a classification or regression algorithm, is to simply import the algorithm you want to use from sklearn, and create a nonconformity function using nonconformist's NcFactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nonconformist.nc import NcFactory\n",
    "\n",
    "nc_dt = NcFactory.create_nc(DecisionTreeClassifier(min_samples_leaf=5))\n",
    "nc_rf = NcFactory.create_nc(RandomForestClassifier(n_estimators=500))\n",
    "nc_knn = NcFactory.create_nc(KNeighborsClassifier(n_neighbors=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "nc_dt = NcFactory.create_nc(DecisionTreeRegressor(min_samples_leaf=5))\n",
    "nc_rf = NcFactory.create_nc(RandomForestRegressor(n_estimators=500))\n",
    "nc_knn = NcFactory.create_nc(KNeighborsRegressor(n_neighbors=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can construct your nonconformity functions manually in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nonconformist.nc import ClassifierNc\n",
    "from nonconformist.base import ClassifierAdapter\n",
    "\n",
    "nc_dt = ClassifierNc(ClassifierAdapter(DecisionTreeClassifier(min_samples_leaf=5)))\n",
    "nc_rf = ClassifierNc(ClassifierAdapter(RandomForestClassifier(n_estimators=500)))\n",
    "nc_knn = ClassifierNc(ClassifierAdapter(KNeighborsClassifier(n_neighbors=11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from nonconformist.nc import RegressorNc\n",
    "from nonconformist.base import RegressorAdapter\n",
    "\n",
    "nc_dt = RegressorNc(RegressorAdapter(DecisionTreeRegressor(min_samples_leaf=5)))\n",
    "nc_rf = RegressorNc(RegressorAdapter(RandomForestRegressor(n_estimators=500)))\n",
    "nc_knn = RegressorNc(RegressorAdapter(RegressorNc(n_neighbors=11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2b: Choosing your error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nonconformist.nc import NcFactory, InverseProbabilityErrFunc, MarginErrFunc\n",
    "\n",
    "nc_proba = NcFactory.create_nc(KNeighborsClassifier(n_neighbors=11), InverseProbabilityErrFunc())\n",
    "nc_margin = NcFactory.create_nc(KNeighborsClassifier(n_neighbors=11), MarginErrFunc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from nonconformist.nc import NcFactory, AbsErrorErrFunc, SignErrorErrFunc\n",
    "\n",
    "nc_abs = NcFactory.create_nc(KNeighborsRegressor(n_neighbors=11), AbsErrorErrFunc())\n",
    "nc_sign = NcFactory.create_nc(KNeighborsRegressor(n_neighbors=11), SignErrorErrFunc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you can construct these manually without leveraging NcFactory as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nonconformist.nc import ClassifierNc, InverseProbabilityErrFunc, MarginErrFunc\n",
    "from nonconformist.base import ClassifierAdapter\n",
    "\n",
    "model = ClassifierAdapter(KNeighborsClassifier(n_neighbors=11))\n",
    "\n",
    "nc_proba = ClassifierNc(model, InverseProbabilityErrFunc())\n",
    "nc_margin = ClassifierNc(model, MarginErrFunc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from nonconformist.nc import RegressorNc, AbsErrorErrFunc, SignErrorErrFunc\n",
    "from nonconformist.base import RegressorAdapter\n",
    "\n",
    "model = RegressorAdapter(KNeighborsRegressor(n_neighbors=11))\n",
    "\n",
    "nc_abs = RegressorNc(model, AbsErrorErrFunc())\n",
    "nc_sign = RegressorNc(model, SignErrorErrFunc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
